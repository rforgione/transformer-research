{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c41f989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dbd1190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 08:39:49.990757: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31d57d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2168e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 08:39:53.334886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-01 08:39:53.352834: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-01 08:39:53.353020: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-01 08:39:54.409287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-01 08:39:54.409627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-01 08:39:54.409644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-01 08:39:54.409890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-01 08:39:54.409931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /device:GPU:0 with 7335 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:09:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0904d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c0f77a",
   "metadata": {},
   "source": [
    "First step is to create an embedding layer that translates raw tokens into K-dimensional embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eacfc38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.0491559   0.04126722 -0.04697653 ... -0.0068565  -0.03183677\n",
      "   -0.03195263]\n",
      "  [ 0.01929628 -0.01089764  0.01000128 ... -0.03021339 -0.01418394\n",
      "   -0.00332562]\n",
      "  [-0.01274476  0.04068748  0.04470846 ... -0.04423631  0.04037298\n",
      "    0.04162011]\n",
      "  ...\n",
      "  [-0.02374609  0.03028352 -0.032427   ...  0.0421473   0.04265909\n",
      "   -0.04501848]\n",
      "  [-0.00558231  0.00323743 -0.03707803 ... -0.02362527 -0.04564954\n",
      "    0.0056197 ]\n",
      "  [-0.03696796 -0.02114703 -0.03012    ... -0.03253096 -0.00911947\n",
      "    0.00583986]]], shape=(1, 10, 768), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Your input text\n",
    "input_text = \"John is the best basketball player I know\"\n",
    "\n",
    "# Tokenize the text\n",
    "input_tokens = tokenizer(input_text, return_tensors=\"tf\", padding=True, truncation=True)\n",
    "\n",
    "# Extract input_ids\n",
    "input_ids = input_tokens[\"input_ids\"]\n",
    "\n",
    "# Create an embedding layer\n",
    "vocab_size = tokenizer.vocab_size  # Size of the BERT vocabulary\n",
    "embedding_dim = 768  # Embedding dimension, which is 768 for BERT-base\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=vocab_size,\n",
    "    output_dim=embedding_dim,\n",
    "    trainable=True,\n",
    ")\n",
    "\n",
    "# Convert token IDs to embeddings\n",
    "token_embeddings = embedding_layer(input_ids)\n",
    "\n",
    "print(token_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
